---
title: "[머피 머신러닝] 1. Introduction"
date: 2025-01-18 15:16:00 +09:00
categories: [스터디, 머피 머신러닝]
tags:
  [
    Probabilistic Machine Learning
  ]
use_math: true
---

# 1. Introduction

## 1.1 **What is machine learning?**

Tom Mitchell의 정의에 따르면, 기계 학습은 다음 세 가지 요소로 구성된다:

- **작업(Task, T)**: 시스템이 수행해야 하는 작업의 종류. 예: 이메일 스팸 필터링.
- **경험(Experience, E)**: 시스템이 학습하기 위해 사용하는 데이터나 학습 신호. 예: 과거의 이메일 데이터.
- **성능 측정(Performance Measure, P)**: 작업 수행 능력을 평가하는 기준. 예: 스팸 필터링 정확도.

이 정의는 학습이란 "경험을 통해 성능이 점점 더 좋아지는 것"으로 본다.

기계 학습은 위 세 가지 요소(T,E,P)의 성질에 따라 다양하게 나뉜다. 예를 들어:

- 학습하고자 하는 작업(T)에 따라 **분류(Classification)**나 **회귀(Regression)** 같은 유형이 존재.
- 경험(E)의 종류에 따라 **지도 학습(Supervised Learning)**, **비지도 학습(Unsupervised Learning)** 등으로 나뉜다.
- 성능 측정 기준(P)은 문제에 따라 정확도, 손실 함수 값 등으로 다를 수 있다.
- 확률적 관점, 확률적 사고에 관하여
    
    이 책은 기계 학습을 "**확률적 관점(probabilistic perspective)**"으로 다루고 있다. 이 접근법은 다음과 같은 이유로 중요하다:
    
    1. **불확실성 하에서의 의사결정 최적화 (Decision making under uncertainty)**
        - 확률적 접근은 미래에 대해 불확실성이 존재할 때 최적의 결정을 내리는 데 유리하다. 예를 들어, 날씨를 예측할 때 단 하나의 값이 아니라, 각 온도에 대한 확률 분포(probability distribution)를 제공함으로써 더 나은 의사결정을 지원한다.
    2. **다른 과학 및 공학 분야와의 연결**
        - 확률적 사고는 통계, 물리학, 경제학 등 여러 학문에서 사용하는 공통 언어다. 따라서 기계 학습을 확률적으로 이해하면 다른 분야와의 융합이 쉬워지고, 새로운 문제를 해결할 때 유리하다.
    
    확률적 관점에서는 다음과 같은 사고방식을 취한다:
    
    - 예측값이나 모델의 매개변수와 같은 미지의 값들을 **확률 변수  (random variables)**로 간주.
    - 이 확률 변수는 하나의 고정된 값이 아니라 여러 가능한 값들의 분포(확률 분포,probability distributions)를 가진다고 본다.
    - 이를 통해 불확실성을 수치적으로 표현하고 다룬다.
    
    확률적 접근은 기계 학습에서 단순히 데이터를 처리하는 것을 넘어, 다른 과학적 문제와 연결되거나 불확실한 상황에서 의사결정을 내리는 데 강력한 도구를 제공한다. 따라서 **확률적 사고(probabilistic thinking)**를 이해하고 숙달하는 것은 기계 학습을 제대로 배우고 활용하기 위해 필수적이다.
    

## **1.2 Supervised Learning**

지도 학습은 입력과 출력의 관계를 학습하는 가장 일반적인 기계 학습 방법으로, 다음의 요소로 구성된다. labelled data with guidance. (label = 정답)

1. **입력 x**: 고정된 차원의 숫자 벡터로 표현되는 특징.
2. **출력 y**: 예측해야 하는 레이블 또는 타겟.
3. **학습 데이터 D**: 입력과 출력의 쌍으로 구성된 데이터셋.
4. **성능 측정 P**: 모델의 예측 능력을 평가하는 기준.

지도 학습은 주어진 학습 데이터셋을 바탕으로 매핑 함수 f를 학습하여, 새로운 데이터 x가 들어왔을 때 적절한 y를 예측할 수 있도록 모델을 만드는 것이 목표다.

### 1.2.1 Classification

**분류 문제(Classification Problem)**는 주어진 입력 데이터를 기반으로 미리 정의된 **클래스(labels)** 중 하나를 예측하는 작업이다. 두 개의 클래스만 예측하는 경우, 이를 **이진 분류(Binary Classification)**라 부른다.

{:.prompt-block}
> **Iris 꽃 분류 문제**
- 꽃받침, 꽃잎의 길이와 너비$X=R^4$를 사용하여 세가지 품종 $Y = \{1,2,3\}$을 예측하는 기초적인 지도학습 문제.(input space, X = numeric features)
- Iris 데이터셋처럼 입력 특징의 개수가 고정된 경우는 데이터를 행렬(샘플수X특징수)로 표현한다.
> 
> 
> ![image.png](assets/img/250118post/image.png)
> 

{:.prompt-block}
> **이미지 데이터 분류 (Image classification)**
- 입력 X는 이미지의 픽셀로 구성되며, 매우 고차원적인 공간이다. (input space , X = set of images)
- C개의 채널(RGB)와 $D_1×D_2$ 크기의 이미지는$X = \mathbb{R}^D$, 여기서 $D = C \times D_1 \times D_2$로 나타낼 수 있다.
- f:x → y
- 이미지를 통해 꽃의 품종을 예측하는 것은 복잡하므로 **합성곱 신경망(CNN, Convolutional Neural Network)** 같은 방법이 활용된다. (14.1장)
> 
> 
> ![image.png](assets/img/250118post/image1.png)
> 

{:.prompt-block}
> **탐색적 데이터 분석(Exploratory Data Analysis, EDA)**
- 기계학습을 시작하기 전에 데이터의 패턴과 문제점을 확인하기 위해 수행된다. 
- 소규모의 테이블형 데이터는 페어플롯을 통해 변수 간 관계를 시각화하고, 고차원 데이터는 차원 축소 후 시각화한다. (차원 축소 방법은 20장) 
- 이런 과정을 통해 적절한 모델 선택과 문제 해결 방안을 구체화할 수 있다.
> 
> 
> ![image.png](assets/img/250118post/image2.png)
> 

{:.prompt-block}
> **분류기 학습(Learning a Classifier)**
> 
> - 간단한 분류 규칙을 통해 입력 공간을 구분하며, 초기 규칙에서 잘못 분류된 영역을 재귀적으로 분할하여 **결정 트리(Decision Tree)**를 생성한다.
> - 각 결정 트리는 각 노드에 특징과 임계값을 저장하여 분류 작업을 수행하며, 결정 경계를 시각적으로 표현할 수 있다.
> - 트리의 매개변수(특징과 임계값)은 학습하는 과정에서 결정된다. (18.1장)
> 
> ![image.png](assets/img/250118post/image3.png)
> 

{:.prompt-block}
> **경험적 위험 최소화(Empirical Risk Minimization)**
> 
> - 말로 풀어서 쓰면 경험적인 리스크를 줄이려고..! 머신러닝은 경험을 통해 배운다. 경험적으로 우리가 데이터셋(경험)을 통해서 리스크(문제를 틀리는 것)를 줄인다는 의미.
> 이를 수학적으로 설명하면 
> ![image.png](assets/img/250118post/image10.png)
> argmin은 L이라는 함수를 최소화하는 세타를 의미함. 
> - 훈련 데이터에서 평균 손실(예: 오분류율)을 최소화하는 매개변수(w와b)를 찾는 과정이다.
> - 단순히 훈련 데이터에서의 성능을 높이는 것이 아니라, 새로운 데이터에서도 잘 작동하도록 **일반화(generalization)**하는 것이 최종 목표다.
> - 특정 상황에서는 손실 함수의 설계를 통해 오류의 심각도(손실함수에서 더 높은 cost를 부여하는 방식)를 반영할 수 있다.
>     - 예를들어 독성이 있는 종자1을 잘못 분류하는 비용은 다른 클래스의 분류 오류보다 더 크게 설정

{:.prompt-block}
> **불확실성(Uncertainty)**
> 
> - 지도 학습에서 불확실성은 모델 불확실성(Epistemic)(모델의 불충분한 학습 등)과 데이터 불확실성(Aleatoric)(입력 출력 관계에 내재된 확률적 특성으로 인한 본질적 불확실성, 동일한 입력이 서로다른 출력을 가지는 경우 등)으로 나뉜다.
> - 불확실성을 조건부 확률로 표현한다.
>     - $p(y=c∣x;θ)=f_c(x;θ)$ : 입력 x가 y에 대해 특정 클래스 c일 확률
>     - 각 클래스일 확률은 0과 1 사이의 값이어야하고, 모든 클래스의 확률 합은 항상 1이어야한다.
> - Softmax 함수로 클래스 레이블의 확률 분포를 계산한다
>     - $ \text{softmax}(a)_c = \frac{e^{a_c}}{\sum_{c'=1}^C e^{a_{c'}}} $
>     - $a = [a_1, a_2, \dots, a_C]$ :클래스 C개에 대한 **logit**(모델의 출력값).
>     - 각 클래스 확률  $0\leq \text{softmax}(a)_c \leq 1$
>     - 모든 클래스 확률의 합 $\sum_{c=1}^C \text{softmax}(a)_c = 1$
> - Logistic Regression은 가중합과 편향을 사용해 확률을 계산하는 간단한 선형 모델이다.
>     - $f(x;θ)=b+w^Tx=b+w_1x_1+w_2x_2+⋯+w_Dx_D$
>     - 여기서 θ=(b,w)는 모델의 매개변수.
>     - w: **가중치(weights)**, b: **편향(bias)**.
> - 편향을 포함한 가중치로 수식을 간소화해 선형 함수 형태$f(x;w)=w^Tx$로 나타낼 수 있다.

{:.prompt-block}
> **최대 우도 추정(Maximum Likelihood Estimation, MLE)**
> 
> - 모델의 조건부 확률 $p(y∣f(x;θ))$을 최대화하는 매개변수θ를 찾는 방법.
> - 학습 과정에서 **음의 로그 우도(Negative Log Likelihood,NLL)**를 손실 함수로 사용하여 최적화를 수행한다. (음의 로그 우도를 최소화)
> - 단일 샘플 손실
>     - $ℓ(y,f(x;θ))=−logp(y∣f(x;θ))$
>     - 좋은 모델은 실제 출력 y에 높은 확률을 할당하므로 -logp의 값(손실)이 작아야한다.
> - 훈련 데이터 전체 손실
>     - $\text{NLL}(\theta) = -\frac{1}{N} \sum_{n=1}^N \log p(y_n \mid f(x_n; \theta))$ : N은 훈련데이터 샘플수. $(x_n,y_n)$:n번째 입력-출력 쌍

{:.prompt-tip}
> **조건부 확률 (Conditional Probability)**
> 하나의 사건이 이미 발생했을 때, 다른 사건이 발생할 확률, 즉 머신러닝에서 조건부 확률은 P(y|x) 는 입력 x가 주어졌을 때 출력 y의 확률을 나타낸다. 



### 1.2.2 Regression

회귀(regression)는 연속적인 출력값을 예측하며, ℓ2 손실(제곱 오차)을 사용해 모델의 잔차를 최소화한다.

- 평균 제곱 오차 (Mean Squared Error, MSE)는 경험적 위험(ERM)을 측정하는 표준 방법이며, NLL과 비례 관계를 가진다. (NLL을 최소화하는 것은 MSE를 최소화하는 것과 동일한 효과를 가진다)
- 회귀에서의 불확실성은 가우시안(정규 분포, Gaussian Distribution)분포를 가정하여 조건부 확률로 모델링한다. $p(y∣x;θ)=N(y∣f(x;θ),σ^2)$
- MLE의 목표는 NLL을 최소화하는 매개변수 θ를 찾는 것이다. MSE를 최소화하는 방식과 동일하다.

{:.prompt-block}
> **선형 회귀(Linear Regression)**
> 
> - 선형 회귀는 출력값 y를 입력값 x의 선형 결합으로 모델링:
>     - 1차원 선형 회귀: $f(x;θ)=b+wx.$
>     - 다중 선형 회귀: $f(x;θ)=b+wTx$ (여러 입력 특징 포함).
> - 매개변수 θ=(w,b)를 학습하여 평균 제곱 오차(MSE)를 최소화.
> - 단순하고 직관적인 회귀 모델로, 다양한 데이터에 적용 가능.
>     - 그러나 입력 특징의 개수(D)가 커질수록 시각화 및 해석이 복잡해질 수 있음.
>         
>         ![image.png](assets/img/250118post/image4.png)
>         
> - 그림 a는 1차원 데이터를 선형 모델로 근사, 그림 b는 잔차를 시각화하여 모델의 목표가 잔차 제곱합을 최소화하는 직선을 학습하는 것임을 보여준다.

{:.prompt-block}
> **다항 회귀(Polynomial Regression)**
> 
> - 다항 회귀는 데이터를 더 잘 설명하기 위해 다항식 변환을 적용한 선형 모델이다.
> - 수식: $f(x;w)=wTϕ(x)$
>     - $\phi(x) = [1, x, x^2, \dots, x^D]$: 입력 데이터를 D-차 다항식으로 변환한 **특징 벡터**.
> - D가 클수록 모델은 복잡해지며 데이터에 더 잘 맞을 수 있지만, 과적합 위험이 커진다.
> - 다차원 입력에서도 적용 가능 : $f(x; w) = w_0 + w_1x_1 + w_2x_2 + w_3x_1^2 + w_4x_2^2$
> - 입력 데이터는 비선형으로 변환하지만, 파라미터 w는 선형이다.
> 
> ![image.png](assets/img/250118post/image5.png)
> 
> - (a) 선형회귀는 단순한 모델로, 데이터의 복잡한 패턴을 설명하기에 한계가 있다.
> - (b) 다항 회귀(이차곡면)는 입력 데이터의 비선형성을 고려하여 더 복잡한 구조를 학습할 수 있다.

{:.prompt-block}
> **딥러닝 (Deep Neural Network,DNN)**
> 
> - 딥러닝 모델은 특징 변환$ϕ(x;V)$ 에 고유의 파라미터 V를 부여함으로써 더욱 강력한 모델을 학습한다.
> - 수식 : $f(x;w,V)=w^Tϕ(x;V)$
> - 딥러닝 모델은 여러 계층(layer)으로 분해하여 구성한다. 이 계층적 추출 방식을 통해 복잡한 데이터를 학습한다.
> 
> ![image.png](assets/img/250118post/image6.png)
> 
> - 위 그림은 다항식 차수에 따른 모델 비교(a,b,c)와 MSE와 차수의 관계 (d)이다.
>     - **(a) Degree 2**: 간단한 이차 다항식으로 데이터의 전반적인 패턴은 캡처하지만 세부적인 변화를 표현하지 못한다.
>     - **(b) Degree 14**: 더 높은 차수로 데이터의 변화를 잘 표현하지만, 일부 과적합(overfitting) 가능성이 있다.
>     - **(c) Degree 20**: 데이터 포인트에 완벽히 맞추지만 지나치게 "복잡한(wiggly)" 모델로 일반화 성능이 떨어진다.
>     - (d) 는 차수가 증가함에 따라 훈련 데이터와 테스트 데이터의 MSE변화를 보여준다. train MSE(파란색)은 차수가 증가할수록 감소하고, test MSE(빨간색)은 차수가 적정 수준을 넘으면 오히려 증가하는 과적합이 발생한다.
> - 차수가 너무 낮으면 데이터 패턴을 충분히 설명하지 못하고 (underfitting), 차수가 너무 높으면 과적합(overfitting)으로 인해 새로운 데이터에 대한 예측력이 떨어진다. 따라서 적절한 차수를 선택하는 것이 중요하다.

### 1.2.3 Overfitting and generalization

- **Empirical Risk (경험적 위험)**
    - $ \mathcal{L}(\theta; \mathcal{D}_{\text{train}}) = \frac{1}{\text{Card}(\mathcal{D}_{\text{train}})} \sum_{(x, y) \in \mathcal{D}_{\text{train}}} \ell(y, f(x; \theta)) $
    - $\mathcal{D}_{\text{train}}$: 훈련 데이터셋.
    - $\ell(y, f(x; \theta))$: 손실 함수(예: MSE).
    - 이 식은 모델이 훈련 데이터에서 얼마나 잘 작동하는지 평가하는 지표인 훈련 손실(Training Loss)를 나타낸다.
    - 충분히 복잡한 모델을 사용하면 훈련 손실을 0으로 만들 수 있다. (예: D=N−1인 다항 회귀). 하지만 이렇게 하면 모델이 **훈련 데이터만 암기**하여 새로운 데이터에 일반화하지 못하는 문제가 발생(과적합)할 수 있다.
- **Population Risk (모집단 위험)**
    - $\mathcal{L}(\theta; p^*) = \mathbb{E}_{p^*}[\ell(y, f(x; \theta))]$
    - $p^*(x, y)$: 데이터가 생성된 실제 분포(알 수 없는 이상적인 분포).
    - Population Risk는 모델의 **이론적인 기대 손실**을 측정하며, 현실적으로 직접 계산할 수 없다.
- **Generalization Gap (일반화 격차)**
    - $\mathcal{L}(\theta; p^*) - \mathcal{L}(\theta; \mathcal{D}_{\text{train}})$
    - 훈련 손실과 모집단 위험의 차이를 의미한다.
    - **과적합(Overfitting):** 훈련 손실은 낮지만 모집단 위험이 높은 경우(일반화 격차가 큰 경우).
- **Test Risk (테스트 위험)**
    - 실제로는 모집단 분포 p∗를 알 수 없으므로 데이터를 훈련 데이터와 테스트 데이터로 나누어 테스트 손실(Test Risk)로 Population Risk를 근사:
    - $\mathcal{L}(\theta; \mathcal{D}_{\text{test}}) = \frac{1}{|\mathcal{D}_{\text{test}}|} \sum_{(x, y) \in \mathcal{D}_{\text{test}}} \ell(y, f(x; \theta))$
- **U-모양 곡선(U-Shaped Curve)**:
    - D=1: 모델이 단순하여 데이터 패턴을 제대로 캡처하지 못한다 (underfitting).
    - D≫1: 모델이 너무 복잡하여 과적합 발생.
    - D가 적절한 경우: 훈련 손실과 테스트 손실이 모두 낮아 일반화 성능이 높다.
- 데이터셋 분할 및 모델 선택
    - 데이터셋을 세 개로 분할:
        1. **훈련 세트 (Training Set)**: 모델 학습에 사용.
        2. **검증 세트 (Validation Set)**: 모델 선택에 사용.
        3. **테스트 세트 (Test Set)**: 최종 성능 평가에 사용.
    - 테스트 세트를 모델 학습이나 선택에 사용하면 안 된다.
    - 대신 **Validation Set**를 활용하여 최적의 모델 복잡도를 찾아야 한다.

### **1.2.4 No free lunch theorem**

**No Free Lunch Theorem**에 따르면, **모든 문제에 대해 항상 최적의 성능을 내는 단일한 모델은 존재하지 않는다**. 즉, 특정 도메인에서 잘 작동하는 모델이 다른 도메인에서는 성능이 좋지 않을 수 있다.

그 이유는 **Inductive Bias (귀납적 편향)** 때문인데, 귀납적 편향은 모델은 항상 데이터에 대한 가정을 기반으로 학습한다는 것을 말한다. 
최적의 모델을 선택하기 위해서는 다음 방법이 필요하다.

- 도메인 지식 (문제의 특성과 데이터의 속성을 잘 이해하고, 해당 도메인에서 적합한 모델을 선택)
- 실험과 검증 (여러 모델을 시도하며, 적합성을 확인. cross validation, Bayesian Methods)

## **1.3 Unsupervised Learning**

![image.png](assets/img/250118post/image8.png)

- 정의 : 라벨 y 없이 입력데이터 $D = \{x_n: n=1, …,N\}$만으로 데이터를 이해하거나 모델링하는 과정
- 목적 : 입력 데이터의 확률 분포 p(x)를 학습하여 새로운 데이터를 생성하거나 고차원의 구조를 이해
- 지도학습에 비한 장점 :  라벨링 작업이 필요없어 시간과 비용 절약 가능, 모호한 카테고리 정의를 피할 수 있음.

비지도 학습은 모델의 입력값으로 입력 데이터만 주어진다. 정답이 없는 모델을 모델에게 요구하는 것이다. 데이터 분석을 통해 unknown pattern을 학습할 수 있게 되고 새로운 데이터가 입력으로 주어졌을때 분류할 수 있게 되는 것이다. 데이터간의 유사도, 패턴, 차이 등으로 데이터를 분류할 수 있는 학습을 진행한다. 

### **1.3.1 Clustering**

클러스터링은 데이터를 특정 기준에 따라 “유사한”점들로 구성된 영역으로 나누는 작업이다. 비지도학습의 대표적인 예시로, 데이터의 라벨이 없을 때 구조를 이해하기 위해 사용된다. 
![image.png](assets/img/250118post/image9.png)

위 그림은 2차원 iris 데이터셋을 세개의 클러스터로 분할한 결과이다. 

클러스터링은 라벨 없이 데이터를 분석하고 구조를 파악하는데 유용해 데이터의 분포를 이해하거나 초기 탐색 단계에서 활용한다. 클러스터의 수에는 정답이 존재하지 않아 데이터의 적합성과 모델 복잡성 간의 균형을 고려해 적절히 결정한다. 

### **1.3.2 Discovering latent “factors of variation”**

잠재적 요인(latent factors of variation)의 개념

- 고차원의 복잡한 데이터를 다룰 때, 데이터를 더 잘 이해하기 위해 특징을 추출해 낮은 차원의 하위 공간으로 투영(projection)하는 것이 유용하다.
- 고차원 데이터 $x_n∈R^D$가 숨겨진 저차원 잠재요인 $z_n \in \mathbb{R}^K$에 의해 생성되었다고 가정했을 때 모델의 구조는 $z_n → x_n$ 과 같고 화살표는 인과관계를 의미한다.

**선형 모델: 요인 분석(FA)**

- 선형 모델을 사용하면 다음과 같은 확률 분포를 정의할 수 있다:
$p(xn∣zn;θ)=N(xn∣Wzn+μ,Σ)$
    - 여기서 W는 선형 변환 행렬, μ는 평균, Σ는 공분산 행렬이다.
- 이 모델을 요인 분석(Factor Analysis, FA)라 한다.
- 이는 선형 회귀와 비슷하지만, $z_n$(입력값)은 관찰되지 않고 $x_n$(출력값)만 관찰된다는 점이 다르다.

**특수 사례 : 확률적 주성분 분석 (PPCA)**

- 공분산 행렬 $Σ=σ^2I$(모든 차원의 분산이 동일하고 서로 상관관계가 없) 인 경우, 요인 분석 모델의 복잡성이 줄어들어 모델은 확률적 주성분 분석 (Probabilistic PCA)이 된다.
    - 요인 분석(FA)은 더 복잡한 공분산 구조를 설명할 수 있지만,$\sigma^2 I$ 가정하에 이러한 복잡성을 제거하고, 단순한 선형 차원 축소 문제로 바뀌게 된다.
- 3차원 데이터(a)를 2차원 선형 하위 공간으로 투영(b)하는 예시
    
    ![image.png](assets/img/250118post/image7.png)
    

**비선형 확장**

- 선형 매핑$z_n \to x_n$은 제약적이므로, 비선형 매핑을 정의해 확장할 수 있다
    
    $p(x_n∣z_n;θ)=N(x_n∣f(z_n;θ),σ^2I)$
    
    - 여기서$f(z_n;θ)$은 비선형 함수이다. (ex: Deep Neural Network)
- 비선형 모델은 매개변수 θ를 추정하고 $z_n$(Neural Network의 입력)을 추론해야하므로 학습이 더 어렵다.

### **1.3.3 Self-supervised learning**

자기지도 학습은 비지도 학습의 한 방식으로, 라벨이 없는 데이터에서 대리 지도 학습 과제(proxy supervised tasks)를 생성하는 접근법이다.(회색조 이미지를 받아 컬러 이미지 예측, 문장에서 빈 단어를 주변 문맥으로 예측 등)

### 1.3.4 Evaluating unsupervised learning

비지도 학습은 정답(Ground Truth)이 없기 때문에 출력의 품질을 평가하기 어렵다.

- **확률 기반 평가**
    - 모델이 보지 않은 테스트 데이터에 할당한 확률을 측정하는 방법
    - 음의 로그 가능도 (negative log likelihood)를 계산
        
        $$
        L(\theta; D) = - \frac{1}{|D|} \sum_{x \in D} \log p(x|\theta)
        $$
        
    - 모델이 데이터 샘플에 높은 확률을 할당하면, 데이터 샘플에 대해 "놀라지 않는다"고 판단.
    - 확률의 합이 1이므로, 데이터가 나타나는 공간에 높은 확률을 할당하면, 데이터가 없는 영역에 낮은 확률을 할당하게 된다.
    - 이를 통해 모델은 데이터의 **전형적인 패턴**을 학습했다고 볼 수 있다.
- **밀도 추정의 한계**:
    - 고차원 데이터에서 밀도 추정은 계산적으로 어렵다.
    - 모델이 데이터에 높은 확률을 할당한다고 해서 반드시 유용한 고수준 패턴을 학습한 것은 아니다(단순히 데이터를 암기했을 수도 있다).

## **1.4 Reinforcement Learning**

강화 학습은 기계 학습의 세 번째 범주로, 에이전트(agent)가 환경과 상호작용하며 최적의 행동 방식을 학습하는 방식이다.

- **정책(policy)** : $a = \pi(x)$
    - x: 환경 상태를 기반으로 하는 입력.
    - a: 에이전트가 수행해야 할 행동.
    - 정책은 환경 상태에 따라 적절한 행동을 결정하는 함수다.
- Supervised Learning(SL)과의 차이점
    - **Supervised Learning(SL)**:
        - 데이터에 **정답 라벨**이 포함되어 있으며, 입력에 대해 올바른 출력을 직접 학습한다.
        - 예: 이미지를 입력받아 "고양이"나 "강아지"로 분류.
    - **Reinforcement Learning(RL)**:
        - 어떤 행동이 최적인지 정답을 알려주지 않는 대신, 에이전트가 행동을 취한 결과에 대해 **보상(reward)** 또는 **벌(punishment)** 신호를 받는다.
        - 이는 "비평가(critic)"로부터 피드백을 받는 것과 비슷하며, "교사(teacher)"로부터 단계별 지침을 받는 것과는 다르다.
- 강화 학습의 어려움
    - **보상 신호의 희소성**
        - 보상 신호가 자주 제공되지 않을 수 있다
        - 예: 체스 게임에서는 한 번의 승패 신호만 제공되며, 이 신호가 어떤 행동에 기인했는지 파악하기 어려움.
    - **크레딧 할당 문제 (Credit Assignment Problem)**
        - 보상이 특정 행동의 결과라는 점을 학습하는 것이 어렵다
        - 예: 게임에서 성공했을 때, 어떤 특정 행동이 성공에 기여했는지 판단하기 어렵다.
- 해결 방안 (추가정보 활용)
    - **전문가 시연(Expert Demonstration):**
        - 예를 들어, 로봇에게 사람이 걸어가는 동작을 보여주고 이를 학습.
        - 이는 감독 학습 방식을 강화 학습에 통합한 형태.
    - **비지도 학습(Unsupervised Learning):**
        - 환경의 구조를 학습하여 에이전트가 더 나은 행동 방식을 발견하도록 도움.
- 해결방안(학습 효율성 개선)
    - 제한된 환경 상호작용을 통해 효과적으로 학습하도록 설계.

## 1.5 Data

샘플 데이터셋 (MNIST, CIFAR10 등)에 대한 설명은 생략한다.